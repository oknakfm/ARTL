{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPLR9oqhs/IIfPrcMM89o6w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Figure 1: Illustration"],"metadata":{"id":"G5XSvNAHl6tL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"equZLPrOllvS"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.linear_model import HuberRegressor\n","from sklearn.metrics import mean_squared_error\n","\n","np.random.seed(42)\n","torch.manual_seed(42)\n","\n","# NN Definition\n","class NeuralNetwork(nn.Module):\n","    def __init__(self, input_dim=2, activation_func='sigmoid'):\n","        super(NeuralNetwork, self).__init__()\n","        self.first = nn.Linear(input_dim, 100)\n","        self.hidden1 = nn.Linear(100, 100)\n","        self.hidden2 = nn.Linear(100, 100)\n","        self.hidden3 = nn.Linear(100, 100)\n","        self.output = nn.Linear(100, 1)\n","        self.activation = nn.Sigmoid() if activation_func == 'sigmoid' else nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.activation(self.first(x))\n","        x = self.activation(self.hidden1(x))\n","        x = self.activation(self.hidden2(x))\n","        x = self.activation(self.hidden3(x))\n","        return self.output(x)\n","\n","# Dataset Generation\n","def generate_data(n=100, noise_std=0.2, outlier_ratio=0.03):\n","    x1 = np.linspace(0, 2 * np.pi, int(np.sqrt(n)))\n","    x2 = np.linspace(0, 2 * np.pi, int(np.sqrt(n)))\n","    x1_grid, x2_grid = np.meshgrid(x1, x2)\n","    X = np.vstack((x1_grid.flatten(), x2_grid.flatten())).T\n","    y_true = np.sin(2 * X[:, 0]) * np.cos(2 * X[:, 1])\n","    y = y_true + np.random.normal(0, noise_std, X.shape[0])\n","\n","    # 外れ値の挿入\n","    n_outliers = int(n * outlier_ratio)\n","    outlier_indices = np.random.choice(n, n_outliers, replace=False)\n","    y[outlier_indices] = 5 + np.random.uniform(-0.1, 0.1, n_outliers)\n","\n","    return X, y, y_true, outlier_indices\n","\n","def plot_3d_surface(X, y, predict_func, title, outlier_indices, y_true):\n","    fig = plt.figure(figsize=(8, 6))\n","    ax = fig.add_subplot(111, projection='3d')\n","\n","    ax.scatter(X[:, 0], X[:, 1], y_true, color='blue', label='True Data')\n","    ax.scatter(X[outlier_indices, 0], X[outlier_indices, 1], y[outlier_indices], color='red', label='Outliers', s=50)\n","\n","    # Plot prediction surface\n","    x1_grid, x2_grid = np.meshgrid(np.linspace(0, 2 * np.pi, 100),\n","                                   np.linspace(0, 2 * np.pi, 100))\n","    X_grid = np.vstack((x1_grid.flatten(), x2_grid.flatten())).T\n","    y_grid_pred = predict_func(X_grid).reshape(x1_grid.shape)\n","\n","    ax.plot_surface(x1_grid, x2_grid, y_grid_pred, cmap='viridis', alpha=0.6)\n","\n","    ax.set_xlabel('x1')\n","    ax.set_ylabel('x2')\n","    ax.set_zlabel('y')\n","    ax.set_title(title)\n","    plt.legend()\n","    plt.show()\n","\n","# Training and Plot Prediction Models\n","def train_and_plot(X, y, y_true, outlier_indices, method, weight_decay=0):\n","    if method == 'Linear+Huber':\n","        model = HuberRegressor()\n","        model.fit(X, y)\n","        predict_func = lambda X_new: model.predict(X_new)\n","    elif method == 'NN+Huber':\n","        model = NeuralNetwork()\n","        optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=weight_decay)\n","        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.5)\n","        criterion = nn.SmoothL1Loss()\n","        X_tensor = torch.tensor(X, dtype=torch.float32)\n","        y_tensor = torch.tensor(y.reshape(-1, 1), dtype=torch.float32)\n","        for epoch in range(5000):\n","            optimizer.zero_grad()\n","            outputs = model(X_tensor)\n","            loss = criterion(outputs, y_tensor)\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","        predict_func = lambda X_new: model(torch.tensor(X_new, dtype=torch.float32)).detach().numpy().flatten()\n","    elif method == 'NN+Tukey':\n","        def tukey_loss(output, target, c=4.685):\n","            residual = target - output\n","            abs_residual = torch.abs(residual)\n","            mask = abs_residual <= c\n","            loss = torch.zeros_like(residual)\n","            loss[mask] = (c**2 / 6) * (1 - (1 - (residual[mask] / c)**2)**3)\n","            loss[~mask] = (c**2 / 6)\n","            return torch.mean(loss)\n","        model = NeuralNetwork()\n","        optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=weight_decay)\n","        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.5)\n","        X_tensor = torch.tensor(X, dtype=torch.float32)\n","        y_tensor = torch.tensor(y.reshape(-1, 1), dtype=torch.float32)\n","        for epoch in range(5000):\n","            optimizer.zero_grad()\n","            outputs = model(X_tensor)\n","            loss = tukey_loss(outputs, y_tensor)\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","        predict_func = lambda X_new: model(torch.tensor(X_new, dtype=torch.float32)).detach().numpy().flatten()\n","    elif method == 'TTL+HOVR(k=2)':\n","        model = NeuralNetwork()\n","        xi = nn.Parameter(torch.zeros(X.shape[0], 1), requires_grad=True)\n","        optimizer = optim.Adam(list(model.parameters()) + [xi], lr=0.01, weight_decay=weight_decay)\n","        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.5)\n","        X_tensor = torch.tensor(X, dtype=torch.float32)\n","        y_tensor = torch.tensor(y.reshape(-1, 1), dtype=torch.float32)\n","        h = int(0.9 * X.shape[0])\n","        lambd = 1e-3\n","        k = 2\n","        q = 2\n","        for epoch in range(5000):\n","            optimizer.zero_grad()\n","            preds = model(X_tensor)\n","            residuals = (y_tensor - preds).view(-1, 1)\n","            loss_fit = (1 / X.shape[0]) * torch.sum((residuals - xi) ** 2)\n","            xi_squared = xi.view(-1) ** 2\n","            T_h_xi = (1 / X.shape[0]) * torch.sum(torch.topk(xi_squared, h, largest=False)[0])\n","            hovr_term = lambd * hovr_regularization(model, X_tensor, k, q)\n","            total_loss = loss_fit + T_h_xi + hovr_term\n","            total_loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","        predict_func = lambda X_new: model(torch.tensor(X_new, dtype=torch.float32)).detach().numpy().flatten()\n","\n","    plot_3d_surface(X, y, predict_func, method, outlier_indices, y_true)\n","\n","\n","\n","# HOVR\n","def hovr_regularization(model, x, k=2, q=2, M=10):\n","    x_min, x_max = x.min(0)[0], x.max(0)[0]\n","    random_points = torch.tensor(np.random.uniform(x_min.numpy(), x_max.numpy(), (M, x.shape[1])), dtype=torch.float32, requires_grad=True)\n","    preds = model(random_points)\n","    grads = torch.autograd.grad(preds, random_points, torch.ones_like(preds), create_graph=True)[0]\n","    hovr_term = 0.0\n","    n_dims = x.shape[1]\n","    for i in range(n_dims):\n","        grad_i = grads[:, i]\n","        temp_grad = grad_i\n","        for _ in range(k - 1):\n","            temp_grad = torch.autograd.grad(temp_grad, random_points, torch.ones_like(temp_grad), create_graph=True)[0][:, i]\n","        hovr_term += (1 / n_dims) * torch.sum(torch.abs(temp_grad) ** q)\n","    return hovr_term\n","\n","# メインスクリプト\n","X, y, y_true, outlier_indices = generate_data()\n","\n","methods = ['Linear+Huber', 'NN+Huber', 'NN+Tukey', 'TTL+HOVR(k=2)']\n","for method in methods:\n","    train_and_plot(X, y, y_true, outlier_indices, method)"]},{"cell_type":"code","source":[],"metadata":{"id":"UzcAaorWl4Xz"},"execution_count":null,"outputs":[]}]}